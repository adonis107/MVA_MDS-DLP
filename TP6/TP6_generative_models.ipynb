{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "# Generative modeling in deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "*This notebook consists of common introductory questions, followed by 4 different generative models (GAN, VAE, Flow matching, Diffusion flow), and a common conclusive question. **Choose & implement 2 among the 4 models**, not all of them! If you train more models, write down below the 2 ones you want to be graded on. Do not forget the last common question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Generative modeling in machine learning can aim at achieving different goals.\n",
    "\n",
    "The first, obvious one is that a generative model can be used to generate more data, to be used afterwards by another algorithm. While a generative model cannot create more information to solve the issue of having too small datasets, it could be used to solve anonymity questions. Typically, sharing a generative model trained on private data could allow the exploitation of the statistical property of this data without sharing the data itself (which can be protected by privacy matters for example).\n",
    "\n",
    "Another goal is to use generative modeling to better understand the data at hand. This is based on the hypothesis that a model that successfully learned to generate (and generalize) a dataset should have internally learned some efficient and compressed representation of the information contained in the data. In this case, analysing a posteriori the learned representation may give us insights on the data itself.\n",
    "\n",
    "The notion of a generative model however needs to be more formally specified, in order to work with. What does it mean for the model to generate data that \"looks like\" the original dataset? A mathematical formulation of that is necessary, in order to define a training objective that can be used efficiently. Having some expert rate the quality of all generated datapoints one by one is definitely not an option.\n",
    "\n",
    "Thus, modeling our data and models as probability distributions comes to the rescue. If we consider our data as coming from some underlying probability distribution, that we will name $p_D$, our goal is thus to train our model to represent another probability distribution, which we will name $p_\\theta$, that should be some good approximation of $p_D$. Given that we only know $p_D$ through some set of realisations from it (the dataset), we can never hope to learn it exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q1: Can you name some metrics that can be used to compare two given distributions $p_D$ and $p_\\theta$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Most comparison methods can be separated into two kinds: those that compare the density of the distributions ($p_\\theta(x)$ vs $p_D(x)$), and those that compare the values sampled from them. These two kinds of approaches have different behavior and trade-offs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q2: Given we want to use them as an optimisation objective, what are the caveats to keep in mind about these two kinds?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "In this work, we will focus on the most widely used generative models based on deep neural networks: Generative Adversarial Networks (GAN), Variational AutoEncoders (VAE), Flow Matching and Diffusion Models, in order to compare them and understand their strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Checkerboard (prioritize this dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_batch(num_datapoints: int) -> np.ndarray:\n",
    "  \"\"\"Checkerboard dataset.\"\"\"\n",
    "  x1 = np.random.rand(num_datapoints) * 4 - 2\n",
    "  x2 = np.random.rand(num_datapoints) - np.random.randint(0, 2, [num_datapoints]) * 2. + np.floor(x1) % 2\n",
    "  data = np.stack([x1, x2]).T * 2\n",
    "  data = (data - data.mean(axis=0)) / data.std(axis=0) # normalize\n",
    "  return torch.from_numpy(data.astype(np.float32))\n",
    "\n",
    "train_data = generate_batch(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(train_data.numpy()[:,0], train_data.numpy()[:,1], s=1.0, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "It's also good to visualize the density as sometimes generative models overfit particular region of space. Once models are trained, when you sample from them, plot the two densities side-by-side to compare real & synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.hist2d(train_data.numpy()[:,0], train_data.numpy()[:,1], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Moon (use this one only if your models struggle on checkerboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Our dataset is mathematically defined, we can generate batches on the fly and enjoy\n",
    "# an infinite-size dataset\n",
    "def generate_batch(batchlen):\n",
    "    \"\"\"This function generates a batch of length 'batchlen' from the dataset\n",
    "    \"\"\"\n",
    "    data = datasets.make_moons(n_samples=batchlen, noise=0.05)[0].astype(np.float32)\n",
    "    return torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Let's plot a large batch, to see what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch = generate_batch(5000)\n",
    "\n",
    "plt.scatter(batch[:,0], batch[:,1], s=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "It's also good to visualize the density as sometimes generative models overfit particular areas. Once models are trained, when you sample from them, plot the two densities side-by-side to compare real & synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "plt.hist2d(batch.numpy()[:,0], batch.numpy()[:,1], bins=100)\n",
    "plt.xlim([-1.2,2.2])\n",
    "plt.ylim([-0.7,1.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "----\n",
    "## Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "GANs structure is based on modeling the distribution $p_\\theta$ as a learned deterministic function applied to a standard noise. Sampling from it is thus done as follows: first, some noise is sampled from a standard N-dimensional Gaussian distribution: $\\epsilon \\sim \\mathcal{N}(0;I)$, and then the output is computed as a deterministic function $x = f_\\theta(\\epsilon)$. The function $f_\\theta$ is implemented as a neural network, $\\theta$ representing its learned parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q3: What is, a priori, the impact of the choice of N, the dimension of the input noise $\\epsilon$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "By construction, this generator structure only allows sampling the distribution $p_\\theta$, and does not allow the computation of the density $p_\\theta(x)$ (at least not without strong assumptions on $f_\\theta$). Such a model thus needs a comparison method based on samples to be trained.\n",
    "\n",
    "The smart idea of GANs is to instead use another neural network to model the objective. Another neural network is introduced: a classifier (that we call the discriminator) which is trained to distinguish examples from the dataset from examples generated by $p_\\theta$. The reasoning is as follows:\n",
    "\n",
    "The discriminator $D$ is trained using a classic classifier loss between the two classes defined as the samples generated by either $p_D$ or $p_\\theta$. This way $D(x)$ can be interpreted as the probability that $x$ came from the real dataset:\n",
    "\n",
    "$$ \\mathcal{L}_D = \\mathbb{E}_{p_D} \\left[ -\\log D(x) \\right] + \\mathbb{E}_{p_\\theta} \\left[ -\\log \\left(1-D(x)\\right) \\right] $$\n",
    "\n",
    "From that, it can be shown that for the generator fixed, the optimal discriminator is given by $D(x) = \\frac{p_D(x)}{p_\\theta(x) + p_D(x)}$, and when reached its loss takes a specific value:\n",
    "\n",
    "$$ \\mathcal{L}_D = 2 \\left( \\log 2 - JSD(p_\\theta \\| p_D) \\right) $$\n",
    ", where JSD is the JS divergence used to measure the similarity of two distributions. \n",
    "$$JSD(p_\\theta \\| p_D) = \\frac{1}{2} \\mathbb{E}_{p_D} \\left[ log(\\frac{2p_D}{p_D+p_\\theta}) \\right] + \\frac{1}{2} \\mathbb{E}_{p_\\theta} \\left[ log(\\frac{2p_\\theta}{p_D+p_\\theta}) \\right]$$\n",
    "So, training the generator network to *maximize* the same loss would, assuming the discriminator is always trained to optimality, minimize the Jensen-Shannon Divergence between $p_\\theta$ and $p_D$, and thus bring $p_\\theta$ closer to $p_D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q4: Can you anticipate a caveat of using the JSD as a training objective for the generator?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here, consider the case where the two distribution are totally different)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Having the generator trained to maximize $\\mathcal{L}_D$ is equivalent to setting its training loss to $ \\mathcal{L}_G = \\mathbb{E}_{p_\\theta} \\log(1-D(x)) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q5: This loss only gives feedback to the generator on samples it generated, what problem may this cause?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We will now work on implementing a GAN on a simple toy problem, to get a feeling of its behavior and test our theoretical insights. For this we will use the `pytorch` library.\n",
    "\n",
    "While a real problem would be generating images for example (each datapoint $x$ would then be a different image), this is a kind of task that easily requires intensive CPU/GPU power, and image datasets are difficult to visualize from a geometric point of view (even small images contains hundreds of pixels, and nobody can visualize points in a 100-dimensional space). So instead we will focus on points in the plane: each datapoint $x$ will actually be a couple of numbers $(x1, x2)$, and our target dataset will be a 2D two-moons shape with some noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We now need to define our two neural networks, the generator and the discriminator. The generator will take as input a value $z$ sampled from a Gaussian prior, and output a value $x$ (thus a couple $(x_1,x_2)$). The discriminator takes as input a value $x$, and is a binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Choose a value for the prior dimension\n",
    "PRIOR_N = 2\n",
    "\n",
    "# Define the generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(PRIOR_N, 2)\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        return self.fc1(z)\n",
    "    \n",
    "    def generate(self, batchlen):\n",
    "        z = torch.normal(torch.zeros(batchlen, PRIOR_N), 1.0)\n",
    "        return self.__call__(z)\n",
    "    \n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 1)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "With these classes in shape, now is only needed the training loop. To stick with the mathematical GAN framework, we should train the discriminator until convergence between each training step of the generator. This is not practical for two reasons: first it takes a lot of time, and second if the discriminator is too good, it will generate vanishing gradients to the generator (as seen in **Q4**).\n",
    "\n",
    "We will thus train the discriminator a fixed number of times between each training iteration of the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "# Number of times to train the discriminator between two generator steps\n",
    "TRAIN_RATIO = 1\n",
    "# Total number of training iterations for the generator\n",
    "N_ITER = 20001\n",
    "# Batch size to use\n",
    "BATCHLEN = 128\n",
    "\n",
    "generator = Generator()\n",
    "optim_gen = torch.optim.Adam(generator.parameters(), lr=0.001, betas=(0.5,0.9))\n",
    "discriminator = Discriminator()\n",
    "optim_disc = torch.optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.5,0.9))\n",
    "\n",
    "for i in range(N_ITER):\n",
    "    # train the discriminator\n",
    "    for _ in range(TRAIN_RATIO):\n",
    "        discriminator.zero_grad()\n",
    "        real_batch = generate_batch(BATCHLEN)\n",
    "        fake_batch = generator.generate(BATCHLEN)\n",
    "        #\n",
    "        # == COMPUTE THE DISCRIMINATOR LOSS HERE ==\n",
    "        #\n",
    "        disc_loss = 0\n",
    "        disc_loss.backward()\n",
    "        optim_disc.step()\n",
    "    # train the generator\n",
    "    generator.zero_grad()\n",
    "    fake_batch = generator.generate(BATCHLEN)\n",
    "    #\n",
    "    # == COMPUTE THE GENERATOR LOSS HERE\n",
    "    #\n",
    "    gen_loss = 0\n",
    "    gen_loss.backward()\n",
    "    optim_gen.step()\n",
    "    if i%1000 == 0:\n",
    "        print('step {}: discriminator: {:.3e}, generator: {:.3e}'.format(i, float(disc_loss), float(gen_loss)))\n",
    "        # plot the result\n",
    "        real_batch = generate_batch(1024)\n",
    "        fake_batch = generator.generate(1024).detach()\n",
    "        plt.scatter(real_batch[:,0], real_batch[:,1], s=2.0, label='real data')\n",
    "        plt.scatter(fake_batch[:,0], fake_batch[:,1], s=2.0, label='fake data')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Complete the previous code and train your model.\n",
    "\n",
    "Depending on your choice of parameters, the training may not go well at all, with the generator completely collapsing quickly at the beginning of the training. It has been observed by the litterature that the generator's loss $\\mathcal{L}_G = \\mathbb{E}_{p_\\theta} \\log(1-D(x))$ is often to blame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q6: Why could we anticipate that this loss could cause this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here, consider about gradient vanishing when discriminator is trained very well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "This issue is solved by replacing the generator loss by an alternative loss: $\\mathcal{L}_G = \\mathbb{E}_{p_\\theta} [ -\\log D(x) ]$ to avoid gradient vanishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q7: Inspect the impact of these different factors:**\n",
    "\n",
    "- depth / width of the generator network\n",
    "- depth / width of the discriminator network\n",
    "- impact of `TRAIN_RATIO`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "For further readings on GANs, you can see the following papers:\n",
    "\n",
    "- Generative Adversarial Networks *(Goodfellow et al.)*: [arXiv:1406.2661](https://arxiv.org/abs/1406.2661)\n",
    "- Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks *(Radford et al.)*: [arXiv:1511.06434](https://arxiv.org/abs/1511.06434)\n",
    "- A Style-Based Generator Architecture for Generative Adversarial Networks *(Karras et al.)* [arxiv:1812.04948v3](https://arxiv.org/abs/1812.04948v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "----\n",
    "## Variational AutoEncoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Another well-known approach to generative modeling is embodied by Variational AutoEncoders (VAEs). While the generative model itself and the procedure to sample it is similar to GANs, the way it is trained is not.\n",
    "\n",
    "The main goal of VAEs is to optimize the likelihood of the real data according to the generative model. In other words, maximize $\\mathbb{E}_{p_D} \\left[\\log p_\\theta(x) \\right ]$, which is equivalent to minimizing $D_{KL}(p_D \\| p_\\theta)$.\n",
    "$$D_{KL}(p_D \\| p_\\theta) = \\mathbb{E}_{p_D}\\left[ log(\\frac{p_D}{p_\\theta}) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q8: Prove this equivalence.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "However, the classes of distributions for which $\\log p_\\theta(x)$ can be analytically computed and optimized is very restricted, and not suitable for real world problems. The main idea of the VAE is thus to introduce a latent variable $z$ and decompose the distribution as: $p_\\theta(x, z) = p_\\theta(x | z) p(z)$. Here $p(z)$ is some fixed prior and $p_\\theta(x | z)$ is a simple distribution whose parameters are the output of a neural network.\n",
    "\n",
    "For example, you could have $p(z)$ be a standard $\\mathcal{N}(0;1)$ and $p_\\theta(x | z)$ be defined as a gaussian $\\mathcal{N}(\\mu_\\theta(z); \\sigma_\\theta(z))$ where $\\mu_\\theta(z)$ and $\\sigma_\\theta(z)$ are created by the neural network you will train. In this case, the resulting distribution $p_\\theta(x) = \\int_z p_\\theta(x|z)p(z)dz$ is an infinite mixture of Gaussians, which is a much more expressive class of distributions.\n",
    "\n",
    "Now, this cannot stop here, as we are not able to analitically compute the density $p_\\theta(x)$. The second main idea of the VAE is to introduce another, auxilliary distribution: $q_\\phi(z | x)$, which will be modelled by a neural network similarly to $p_\\theta(x | z)$. Introducing it allows us to create a lower bound for $\\log p_\\theta(x)$:\n",
    "\n",
    "$$\\log p_\\theta(x) = \\mathbb{E}_{z \\sim q_\\phi} \\log p_\\theta(x) = \\mathbb{E}_{z \\sim q_\\phi} \\left[ \\log p_\\theta(x) \\frac {q_\\phi(z|x)}{q_\\phi(z|x)} \\right]$$\n",
    "\n",
    "Following Bayes theorem, $p_\\theta(x) p_\\theta(z|x) = p_\\theta(x, z) = p_\\theta(x|z) p(z)$, so we get:\n",
    "\n",
    "$$\\log p_\\theta(x) = \\mathbb{E}_{z \\sim q_\\phi} \\left[ \\log \\frac{p_\\theta(x|z) p(z)}{p_\\theta(z|x)} \\frac {q_\\phi(z|x)}{q_\\phi(z|x)} \\right]$$\n",
    "\n",
    "Re-organizing the terms:\n",
    "\n",
    "$$\\log p_\\theta(x) = \\mathbb{E}_{z \\sim q_\\phi} \\log \\frac{q_\\phi(z|x)}{p_\\theta(z|x)} + \\mathbb{E}_{z \\sim q_\\phi} \\log \\frac{p(z)}{q_\\phi(z|x)} + \\mathbb{E}_{z \\sim q_\\phi} \\log p_\\theta(x | z)$$\n",
    "\n",
    "This can be re-expressed like so:\n",
    "\n",
    "$$\\log p_\\theta(x) = D_{KL}(q_\\phi(z | x) \\| p_\\theta(z | x)) - D_{KL}(q_\\phi(z | x) \\| p(z)) + \\mathbb{E}_{z \\sim q_\\phi} \\log p_\\theta(x|z)$$\n",
    "\n",
    "The 3 terms of this equality can be interpreted like so:\n",
    "\n",
    "- the first term measures how much $q_\\phi(z | x)$ is similar to $p_\\theta(z | x)$, or in other words is a good inverse of $p_\\theta(x | z)$\n",
    "- the second term measures how similar $q_\\phi(z|x)$ is from the latent prior $p(z)$\n",
    "- the third term is linked to how likely $p_\\theta$ is to yield the given $x$ when $z$ is sampled from $q_\\phi(z | x)$ rather than $p(z)$\n",
    "\n",
    "It is interesting to note that the first term, being a KL-divergence is always positive. As such the combination of the last two terms forms a lower bound of $\\log p_\\theta(x)$ which *can* be computed and used as a training objective. This bound is called the *Evidence Lower-Bound (ELBO)*. Simply flipping its sign can make it into a loss that can be minimized by gradient descent:\n",
    "\n",
    "$$ \\mathcal{L}_{ELBO} = D_{KL}(q_\\phi(z | x) \\| p(z)) + \\mathbb{E}_{z \\sim q_\\phi} [ - \\log p_\\theta(x|z) ]$$\n",
    "\n",
    "From this formulation comes the parallel with auto-encoders that give the VAE its name: $q_\\phi(z | x)$ can be seen as a *probabilistic encoder* from the data $x$ to the latent space $z$, and $p_\\theta(x | z)$ can be seen as a *probabilistic decoder* from the latent space $z$ to the data $x$. In this case the second term of $\\mathcal{L}_{ELBO}$ is the loss measuring the reconstruction quality of the auto-encoder, and the first term can be seens as a regularization of the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "![VAE](./vae-gaussian.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q9: We can see that $p(z)$ is never sampled during the training process, how can that be a problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here, what will be the influence on data generation by VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "A typical choice to represent $q_\\phi(z | x)$ is to use a diagonal Gaussian distribution $\\mathcal{N}(\\mu_\\phi(x); Diag(\\sigma_\\phi^2(x)))$, which makes the KL-divergence term of $\\mathcal{L}_{ELBO}$ analytically computable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q10: Assuming $p(z)$ is a $\\mathcal{N}(0; Id)$ gaussian, what is the value of $D_{KL}(q_\\phi(z | x) \\| p(z))$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We will also model $p_\\theta(x | z)$ as a diagonal Gaussian $\\mathcal{N}(\\mu_\\theta(z); Diag(\\sigma_\\theta^2(z)))$.\n",
    "\n",
    "\n",
    "**Note:** For the following, be careful about the difference between $\\mu_\\phi, \\sigma_\\phi$ which define the Gaussian distribution of the *encoder* $q_\\phi$ and $\\mu_\\theta, \\sigma_\\theta$ which define the Gaussian distribution of the *decoder* $p_\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q11: What is the expression of $-\\log p_\\theta(x | z)$ for given $x$ and $z$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We will build and train a VAE using the same dataset as previously, in order to compare its behavior to GANs. For numerical stability, we will interpret the output of the encoder and decoder networks as $(\\mu, \\log\\sigma^2)$, rather than $(\\mu, \\sigma)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "# Choose a value for the latent dimension\n",
    "LATENT_N = 10\n",
    "\n",
    "# Define the generator\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_mu = nn.Linear(2, LATENT_N)\n",
    "        self.fc_logvar = nn.Linear(2, LATENT_N)\n",
    "        \n",
    "    # encode a datapoint. This should return a couple of tensors (mu, logvar) representing\n",
    "    # the parameters of the Gaussian q_\\phi(z | x)\n",
    "    def __call__(self, x):\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return (mu, logvar)\n",
    "    \n",
    "\n",
    "# Define the discriminator\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_mu = nn.Linear(LATENT_N, 2)\n",
    "        self.fc_logvar = nn.Linear(LATENT_N, 2)\n",
    "    \n",
    "    # decode a datapoint. This should return a couple of tensors (mu, logvar) representing\n",
    "    # the parameters of the Gaussian p_\\theta(z | x)\n",
    "    def __call__(self, z):\n",
    "        mu = self.fc_mu(z)\n",
    "        logvar = self.fc_logvar(z)\n",
    "        return (mu, logvar)\n",
    "\n",
    "    def generate(self, batchlen):\n",
    "        z = torch.normal(torch.zeros(batchlen, LATENT_N), 1.0)\n",
    "        (mu, logvar) = self.__call__(z)\n",
    "        return torch.normal(mu, torch.exp(0.5*logvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "From this, the parameters of both networks are trained conjointly using the same loss $\\mathcal{L}_{ELBO}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "# Total number of training iterations for the VAE\n",
    "N_ITER = 40001\n",
    "# Batch size to use\n",
    "BATCHLEN = 128\n",
    "\n",
    "encoder = Encoder()\n",
    "optim_enc = torch.optim.Adam(encoder.parameters(), lr=0.001, betas=(0.5,0.9))\n",
    "decoder = Decoder()\n",
    "optim_dec = torch.optim.Adam(decoder.parameters(), lr=0.001, betas=(0.5,0.9))\n",
    "\n",
    "for i in range(N_ITER):\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    \n",
    "    x = generate_batch(BATCHLEN)\n",
    "    \n",
    "    enc_mu, enc_logvar = encoder(x)\n",
    "    #\n",
    "    # COMPUTE THE KL PART OF THE LOSS HERE\n",
    "    #\n",
    "    loss_kl = 0\n",
    "    #\n",
    "    # SAMPLE z FROM q(z|x) HERE\n",
    "    #\n",
    "    z = 0\n",
    "    \n",
    "    dec_mu, dec_logvar = decoder(z)\n",
    "    #\n",
    "    # COMPUTE THE RECONSTRUCTION PART OF THE LOSS HERE\n",
    "    #\n",
    "    loss_rec = 0\n",
    "    \n",
    "    (loss_kl + loss_rec).backward()\n",
    "    optim_enc.step()\n",
    "    optim_dec.step()\n",
    "    if i%1000 == 0:\n",
    "        print('step {}: KL: {:.3e}, rec: {:.3e}'.format(i, float(loss_kl), float(loss_rec)))\n",
    "        # plot the result\n",
    "        real_batch = generate_batch(1024)\n",
    "        rec_batch = torch.normal(dec_mu, torch.exp(0.5*dec_logvar)).detach()\n",
    "        fake_batch = decoder.generate(1024).detach()\n",
    "        plt.scatter(real_batch[:,0], real_batch[:,1], s=2.0, label='real data')\n",
    "        plt.scatter(rec_batch[:,0], rec_batch[:,1], s=2.0, label='rec data')\n",
    "        plt.scatter(fake_batch[:,0], fake_batch[:,1], s=2.0, label='fake data')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q12: Try hardcoding $\\sigma_\\theta(z)$ to some small value (like 1E-4) rather than allowing the decoder to learn it. What does it change?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here, observe the plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q13: How do the power of encoder and decoder affect the overall training of the VAE?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "---\n",
    "## Flow Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Another approach to generative modeling is given by Normalizing flows. The idea is to learn a mapping $f$ from the data distribution $p_D$ (defined over a space $\\mathcal{X}$) to a known distribution (typically, a normal distribution) from which we know how to sample. Two key points are to be noted:\n",
    "1. The mapping needs to be bijective (i.e., the network needs to be invertible).\n",
    "2. The exact likelihood of a data point should be easily computable.\n",
    "\n",
    "For the implementation we will use Flow Matching, an approach for training Continuous Normalizing Flows based on regressing vector fields of fixed conditional probability paths.\n",
    "Before diving into Flow Matching, letâ€™s first clarify:\n",
    "\n",
    "- A **vector field** is a mathematical object that assigns a vector to every point in a space. We can think of it as a function that describes the direction and speed of movement at every possible location.\n",
    "\n",
    "- A **flow** is the trajectory that a point follows when it moves according to the directions given by the vector field over time. In general, data points evolve when guided by a vector field.\n",
    "\n",
    "\n",
    "Let us denote $\\renewcommand{\\R}{\\mathbb{R}} v : [0,1] \\times \\R^d \\to \\R^d $ a time-dependent vector field and $\\phi : [0,1] \\times \\R^d \\to \\R^d$ a flow. A flow is related to a vector field $v_t$ as:\n",
    "$$\n",
    "\\frac{d}{dt}\\phi_t(x) = v_t(\\phi_t(x))\n",
    "$$\n",
    "$$\n",
    "\\phi_0(x) = x\n",
    "$$\n",
    "\n",
    "The main idea of Flow Matching is to use a neural network to model the vector field $v_t$, which implies that $\\phi_t$ will also be a parametric model simulating a Continuous Normalizing Flow (CNF). In the context of generative modeling, the CNF allows us to transform a simple prior distribution (e.g. Gaussian) $p_z$ into a more complex one $p_x$, which will be hopefully close enough to the data distribution $p_D$. To comply with the time-dependent framework, we assume a transition between $p_z$ and $p_x$ in a range $[0,1]$ so $p_z = p_0$ and $p_x = p_1$. We proceed by using the push-forward equation:\n",
    "$$\n",
    "p_t = [\\phi_t]*p_0\n",
    "$$\n",
    "where $\\forall x \\in \\R^2$:\n",
    "$$\n",
    "[\\phi_t]*p_0(x) := p_0(\\phi^{-1}(x)) \\; \\det\\Big[ \\frac{\\delta \\phi_t^{-1}}{\\delta x} (x) \\Big]\n",
    "$$\n",
    "\n",
    "So the flow $\\phi$ acts as the mapping $f$ in this context. If you are not familiar with images of distributions, the definition is here: https://en.wikipedia.org/wiki/Pushforward_measure ; it can be defined as the measure that satisfies this change of variables: $\\int_{z\\sim p_\\mathcal{N}} g(f^{-1}(z)) dz = \\int_{x\\sim p_{G}} g(x) dx$ for all functions $g$. Another notation for this is $\\int_{z} g(f^{-1}(z)) \\;dp_\\mathcal{N}(z) = \\int_{x} g(x) \\;dp_{G}(x)$. \n",
    "\n",
    "Thus Flow Matching aims to learn the true vector field $u_t$:\n",
    "$$\n",
    "L_{CFM}(\\theta) = \\mathbb{E}_{t,p_D(x_1),p_t(x|x_1)} || v_t(x) - u_t(x|x_1) ||^2\n",
    "$$\n",
    "> **Attention! Mind the difference in notation between the true vector $u$ and its estimation $v$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "### Optimal Transport Conditional Vector Fields\n",
    "\n",
    "We will use the simplest approach where the flow $\\phi$ is a linear displacement.\n",
    "\n",
    "Let $x_1 \\sim p_D(x_1)$ be a point from the dataset. We can define the conditional flow $\\psi_t$ (conditional version of $\\phi_t$) to be the Optimal Transport displacement map between the two Gaussians $p_0(x|x_1)$ and $p_1(x|x_1)$, that is: \n",
    "\\begin{equation}\n",
    "\\psi_t(x) = (1 - (1 - \\sigma_{min})t)x + tx_1\n",
    "\\end{equation}\n",
    "(we can prove that $\\psi_t$ satisfies the push-forward equation).\n",
    "\n",
    "In the case of Optimal Transport conditional VFs the conditional flow matching objective loss can be written as follows: \n",
    "$$\n",
    "L_{CFM}(\\theta) = \\mathbb{E}_{t,p_D(x_1),p(x_0)} ||v_t(\\psi_t(x_0)) - \\frac{d}{dt}\\psi_t(x_0)||^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q14: Express the derivative of $\\psi_t(x_0)$, to simplify the formula of $L_{CFM}(\\theta)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q15: Calculate the determinant of the Jacobian of the flow $\\phi_t(x)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q16: Using the Jacobian determinant, prove that $\\psi_t(x)$ is indeed invertible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q17: Prove that $\\psi_t(x)$ satisfies the push-forward equation. That means that it applies scaling and shifting to the distribution $p_0(x)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We sample $x_1 \\sim p_D(x_1)$ (samples from the dataset), $x_0 \\sim p(x_0)$ (samples from the prior distribution) and $t \\sim \\text{Unif}([0,1])$. We need to apply a little trick for time sampling since the batch covers the range $[0,1]$ uniformly with a random offset. Then we compute an approximation of the CFM Loss on the batch:\n",
    "$$\n",
    "L_{batch}(\\theta) = \\frac{1}{N} \\sum_{i=0}^{N-1} ||v_t(\\psi_t(x_0^{(i)})) - (x_1^{(i)} - (1 - \\sigma_{min})x_0^{(i)})||^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q18: Fill the Coupling layer structure below by defining suitable functions sfun and tfun (using a final tanh in sfun is highly recommended) and the inverse pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "class OptimalTransportFlowMatching:\n",
    "    def __init__(self, sig_min: float = 0.001) -> None:\n",
    "        super().__init__()\n",
    "        self.sig_min = sig_min\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def psi_t(self, x: torch.Tensor, x_1: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Conditional Flow\n",
    "        \"\"\"\n",
    "        #\n",
    "        # COMPUTE THE CONDITIONAL FLOW HERE\n",
    "        #\n",
    "        return None\n",
    "\n",
    "    def loss(self, v_t: nn.Module, x_1: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Compute loss\n",
    "        \"\"\"\n",
    "        # t ~ Unif([0, 1])\n",
    "        # the batch covers the range [0,1] uniformly with a random offset\n",
    "        t = (torch.rand(1, device=x_1.device) + torch.arange(len(x_1), device=x_1.device) / len(x_1)) % (1 - self.eps)\n",
    "        t = t[:, None].expand(x_1.shape) # turn 2d\n",
    "        \n",
    "        #\n",
    "        # SAMPLE THE PRIOR DISTRIBUTION HERE\n",
    "        # x_0 ~ p(x_0)\n",
    "        #\n",
    "        \n",
    "        #\n",
    "        # CALCULATE THE BATCH LOSS HERE\n",
    "        #\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "### Conditional Vector Field\n",
    "\n",
    "We add the Conditional Vector Field class which aims to model the Optimal Transport Conditional Vector Field $v_t$. This approximation $v_t(\\cdot;\\theta)$ of the true $v_t$ will be optimized by tuning the parameters $\\theta$ of ConditionalVectorField.\n",
    "\n",
    "Once optimized, we need to sample from the learned flow, thus we define the encode and decode functions:\n",
    "- `encode` maps the data distribution $p_D(x_1) \\approx p_1(x_1)$ to the prior distribution $p(x_0)$.\n",
    "- `decode` maps the prior distribution $p(x_0)$ to the data distribution $p_1(x_1) \\approx p_D(x_1)$.\n",
    "\n",
    "A flow $\\phi_t$ and its corresponding vector field $v_t$ verify the following equations:\n",
    "$$\n",
    "\\frac{d}{d_t}\\phi_t(x) = v_t(\\phi_t(x))\n",
    "$$\n",
    "$$\n",
    "\\phi_0(x) = x\n",
    "$$\n",
    "Thus, to encode we integrate the first equation from $t=1$ to $t=0$ and the decode function is the same but going from $t=0$ to $t=1$.\n",
    "We use the Euler method to encode and decode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "class ConditionalVectorField(nn.Module):\n",
    "    def __init__(self, net: nn.Module, n_steps: int = 100, dt: float = 0.01) -> None:\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.n_steps = n_steps\n",
    "        self.dt = dt\n",
    "\n",
    "    def forward(self, t: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(t, x)\n",
    "        \n",
    "    def wrapper(self, t: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "        t = t * torch.ones(len(x), device=x.device)\n",
    "        return self(t, x)\n",
    "\n",
    "    def encode(self, x_1: torch.Tensor) -> torch.Tensor:\n",
    "        x = x_1\n",
    "        t = torch.ones(x.shape[0], device=x.device)  # Start from t=1\n",
    "        for _ in range(self.n_steps):\n",
    "            v = self.wrapper(t, x)\n",
    "            x = x - self.dt * v  # Reverse Euler update\n",
    "            t = t - self.dt  # Decrement time\n",
    "        return x\n",
    "\n",
    "    def decode(self, x_0: torch.Tensor) -> torch.Tensor:\n",
    "        x = x_0\n",
    "        t = torch.zeros(x.shape[0], device=x.device)\n",
    "        for _ in range(self.n_steps):\n",
    "            v = self.wrapper(t, x)\n",
    "            x = x + self.dt * v # Euler update\n",
    "            t = t + self.dt # Step increment\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "### Neural Network for VF approximation\n",
    "\n",
    "We want to approximate $v_t$ with a parametric model $v_t(\\cdot;\\theta)$. Since we deal with point coordinates and want to keep the neural network simple for this example, we use a simple Multilayer Perceptron.\n",
    "\n",
    "However the vector field $v$ is conditioned on time $t$. Thus, we create a sinusoidal positional encoding of $t$ thanks to sine and cosine functions to have a time representation that is easier to exploit than just its value between 0 and 1.\n",
    "\n",
    "When computing $v_t(x)$ we simply concatenate the sinusoidal positional encoding of $t$ with $x$ (input coordinates), and then process the obtained tensor with the MLP's layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, h_dims: list[int], n_frequencies:int) -> None:\n",
    "        super().__init__()\n",
    "        ins = [in_dim + 2 * n_frequencies] + h_dims\n",
    "        outs = h_dims + [out_dim]\n",
    "        self.n_frequencies = n_frequencies\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(in_d, out_d), nn.LeakyReLU()) for in_d, out_d in zip(ins, outs)\n",
    "        ])\n",
    "        self.top = nn.Sequential(nn.Linear(out_dim, out_dim))\n",
    "    \n",
    "    def time_encoder(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        freq = 2 * torch.arange(self.n_frequencies, device=t.device) * torch.pi\n",
    "        t = freq * t[..., None]\n",
    "        return torch.cat((t.cos(), t.sin()), dim=-1)\n",
    "        \n",
    "    def forward(self, t: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "        t = self.time_encoder(t)\n",
    "        x = torch.cat((x, t), dim=-1)\n",
    "        \n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.top(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "# globals\n",
    "BATCH_SIZE = 128\n",
    "LOG_INTERVAL = 50\n",
    "N_EPOCHS = 10\n",
    "INPUT_SIZE = 2\n",
    "OUTPUT_SIZE = 2\n",
    "HIDDEN_SIZE = 256\n",
    "N_LAYERS = 5\n",
    "TIME_FREQUENCY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "# data loading\n",
    "train_data = generate_batch(50000)\n",
    "test_data = generate_batch(1000)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loader_kwargs = {\"num_workers\": 1, \"pin_memory\": True} if device == \"cuda\" else {}\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "model = OptimalTransportFlowMatching()\n",
    "net = Net(INPUT_SIZE, OUTPUT_SIZE, [HIDDEN_SIZE]*N_LAYERS, TIME_FREQUENCY).to(device)\n",
    "v_t = ConditionalVectorField(net)    \n",
    "\n",
    "losses = [] \n",
    "# configure optimizer\n",
    "optimizer = torch.optim.Adam(v_t.parameters(), lr=1e-3)\n",
    "n_epochs = 5000\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for batch_idx, x_inputs in enumerate(train_loader):\n",
    "        x_1 = x_inputs.to(device)\n",
    "        # compute loss \n",
    "        loss = model.loss(v_t, x_1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += [loss.detach()]\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(x_inputs), len(train_data),\n",
    "                100. * batch_idx / len(train_loader), loss / len(x_inputs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "### Sampling\n",
    "\n",
    "To sample $\\hat{x}_1 \\sim p_D(x_1)$, we first sample $x_0 \\sim p(x)$, drawing samples from the prior distribution, and then apply the decode function from the ConditionalVectorField class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "# \n",
    "# SAMPLE THE PRIOR AND DECODE HERE\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# PLOT THE DENSITY HERE\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q19: Explain why Normalizing flows do not fit well when there are many clusters in the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "---\n",
    "## Denoising Diffusion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Recently Diffusion Models received a lot of attention. __Diffusion Models Beat GANs on Image Synthesis__ *(Dhariwal,Nichol)* : [arXiv:2105.05233](https://arxiv.org/pdf/2105.05233.pdf) shows significant improvement on image generation with a model claimed to be easier to train than GANs.\n",
    "\n",
    "\n",
    "It is the key of the image generating process behind Latent Diffusion models such as Dall.e, Imagen or StableDiffusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We are going to implement a model inspired by the paper\n",
    "__Denoising Diffusion Probabilistic Models__  *(Ho et al.)*: [arXiv:2006.11239](https://arxiv.org/pdf/2006.11239.pdf) \n",
    "\n",
    "\n",
    " Denoising diffusion probabilistic model  introduce noise into data and gradually learn to reverse this process for generating new samples. It involves two Markov chains, one that forwards data to noise, and another that reverses this process by converting the noise back to data. The forward chain is usually designed to transform any data distribution into a simpler prior distribution, such as a standard Gaussian distribution, while the reverse Markov chain is parametrized by a neural network and learns to reverse this process. To generate new data points, we first sample a random vector from the prior distribution, then applies ancestral sampling through the reverse Markov chain.\n",
    "\n",
    " References:\n",
    "\n",
    "- Survey on Diffusion Models : https://arxiv.org/pdf/2209.00796.pdf\n",
    "- https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\n",
    "- https://blog.alexalemi.com/diffusion.html\n",
    "- https://sander.ai/posts/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "![Denoisingdiagram](./illustrationDenoising.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "$q$ and $p_{\\theta}$ being the respective kernels of the two chains. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Forward Pass ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "For our purpose we are going to use a Gaussian Noise. The forward Kernel will have the following shape : \n",
    "\n",
    "$$q(x_t| x_{t-1}) = \\mathcal{N}(x_t;\\sqrt{1- \\beta_t} x_{t-1},\\beta_t I )$$\n",
    "\n",
    "with $\\mathcal{N}(x;\\mu,\\sigma I )$ a conditional gaussian :\n",
    "$$ y \\sim \\mathcal{N}(x;\\mu,\\sigma I ) \\equiv y|x \\sim  \\mathcal{N}(\\mu,\\sigma I )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q20: What does $\\beta_t$ represent in the formula ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "In our example the sequence $\\beta_t$ will be chosen linearly wrt $t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We introduce $\\alpha_t := 1-\\beta_t$ and $\\overline{\\alpha_t} = \\prod_{s=1}^{t} \\alpha_s$ we can sample forward directly at timestep $t$ from the original image : \n",
    "$$q(\\mathbf{x}_{1:T}|\\mathbf{x}_0) = \\prod_{t=1}^{T}q(\\mathbf{x}_t|\\mathbf{x}_{t-1})$$\n",
    "$$ q(\\mathbf{x}_t| \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t;\\sqrt{\\overline{\\alpha_t}} \\mathbf{x}_0, (1-\\overline{\\alpha_t})I)$$\n",
    "\n",
    "i.e. \n",
    "\\begin{align}\n",
    "\\boldsymbol{x}_t = \\sqrt{\\bar{\\alpha}_t} \\boldsymbol{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon} \\;\\;\\; \\text{where} \\; \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\n",
    "\\end{align}\n",
    "\n",
    "we will then fix $$\\sigma_t = \\sqrt{1 - \\bar{\\alpha}_t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q22:  Implement the forward pass using $\\overline{\\alpha_t}$ (Hint : you may need to precalculate the $\\overline{\\alpha_t}$ from $\\beta_t$)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "def bcast_right(x: torch.Tensor, ndim: int) -> torch.Tensor:\n",
    "    \"\"\"Util function for broadcasting to the right.\"\"\"\n",
    "    if x.ndim > ndim:\n",
    "        raise ValueError(f'Cannot broadcast a value with {x.ndim} dims to {ndim} dims.')\n",
    "    elif x.ndim < ndim:\n",
    "        difference = ndim - x.ndim\n",
    "        return x.view(x.shape + (1,) * difference)\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "class DiscreteDDPMProcess:\n",
    "    \"\"\"A Gaussian diffusion process: q(xt|x0) = N(sqrt_alpha_bar(t)*x0, sigma(t)^2 * I),\n",
    "    which implies the following transition from x0 to xt:\n",
    "\n",
    "    xt = sqrt_alpha_bar(t) x0 + sigma(t) eps, eps ~ N(0, I).\n",
    "\n",
    "    Diffusion processes differ in how they specify sqrt_alpha_bar(t) and/or sigma(t).\n",
    "    Here we follow the DDPM paper.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_diffusion_timesteps: int = 1000,\n",
    "        beta_start: float = 0.0001,\n",
    "        beta_end: float = 0.02,\n",
    "    ):\n",
    "        self._num_diffusion_timesteps = num_diffusion_timesteps\n",
    "        self._beta_start = beta_start\n",
    "        self._beta_end = beta_end\n",
    "        self._betas = np.linspace(self._beta_start, self._beta_end, self._num_diffusion_timesteps)\n",
    "\n",
    "        alphas_bar = self._get_alphas_bar()\n",
    "        ###############\n",
    "        # TO COMPLETE #\n",
    "        ###############\n",
    "        self._sqrt_alphas_bar = ? #put in dtype=torch.float32\n",
    "        self._sigmas = ? #put in dtype=torch.float32\n",
    "\n",
    "    @property\n",
    "    def tmin(self):\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def tmax(self):\n",
    "        return self._num_diffusion_timesteps\n",
    "\n",
    "    def _get_alphas_bar(self) -> np.ndarray:\n",
    "        ###############\n",
    "        # TO COMPLETE #\n",
    "        ###############\n",
    "        alphas_bar = ?\n",
    "\n",
    "        # we can add this 1 in front to simplify indexing,\n",
    "        # and to make alpha[0]=1 and sigma[0]=0.\n",
    "        # these values at t=0 will be needed later when generating samples\n",
    "        alphas_bar = np.concatenate(([1.], alphas_bar))\n",
    "\n",
    "        return alphas_bar\n",
    "\n",
    "    def sqrt_alpha_bar(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self._sqrt_alphas_bar[t.long()]\n",
    "\n",
    "    def sigma(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self._sigmas[t.long()]\n",
    "\n",
    "    def sample(self, x0: torch.Tensor, t: torch.Tensor, eps: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Draws samples from the forward diffusion process q(xt|x0).\"\"\"\n",
    "        ###############\n",
    "        # TO COMPLETE #\n",
    "        ###############\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "# data loading\n",
    "test_data = generate_batch(1000)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "process = DiscreteDDPMProcess(num_diffusion_timesteps=1000)\n",
    "ts = torch.Tensor(np.linspace(process.tmin, process.tmax, num=process.tmax, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(4 * 2, 2))\n",
    "\n",
    "# plot how sqrt_alpha_bar and sigma change over time\n",
    "ax[0].plot(ts.numpy(), process.sigma(ts), label=r'$\\sigma$')\n",
    "ax[0].plot(ts.numpy(), process.sqrt_alpha_bar(ts), label=r'$\\sqrt{\\bar\\alpha}$')\n",
    "ax[0].set_xlabel('time')\n",
    "ax[0].legend()\n",
    "\n",
    "# It is often helpful to reason in terms of signal-to-noise ratio:\n",
    "# SNR = sqrt_alpha_bar(t)^2 / sigma(t)^2 or more conveniently, its logarithm.\n",
    "# High SNR = little noise, low SNR = a lot of noise.\n",
    "lambda_ = [2. * np.log(process.sqrt_alpha_bar(t) / process.sigma(t)) for t in ts]\n",
    "ax[1].plot(ts.numpy(), lambda_, c='g', label=r'$log SNR$')\n",
    "ax[1].set_xlabel('time')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "# Effect on the distribution\n",
    "torch_test_data = torch.Tensor(test_data)\n",
    "def apply_on_dataset(dataset,t):\n",
    "    dataset_t = torch.zeros_like(dataset)\n",
    "    for i in range(dataset.shape[0]):\n",
    "        point = dataset[i]\n",
    "        eps = torch.randn_like(point)\n",
    "        point_t = process.sample(point, t, eps)\n",
    "        dataset_t[i] = point_t\n",
    "    return dataset_t\n",
    "\n",
    "fig,axes = plt.subplots(1,5,figsize=(20,5))\n",
    "axes[0].scatter(torch_test_data[:,0],torch_test_data[:,1])\n",
    "for i in range(1,5):\n",
    "    t = torch.Tensor([i*50]).type(torch.int64)\n",
    "    dataset_t = apply_on_dataset(torch_test_data,t)\n",
    "    axes[i].scatter(dataset_t[:,0],dataset_t[:,1])\n",
    "    axes[i].set_title(f\"After {t.detach().item()} walks\")\n",
    "fig.suptitle(\"Influence of the forward pass on the distribution\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Backward Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Hypothetically, We would like  to train the reverse kernel $p_\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t\\right)$, with parameters $\\theta$ parametrized by a neural network \n",
    "\n",
    "$$\n",
    "p_\\theta\\left(\\mathbf{x}_{0: T}\\right):=p\\left(\\mathbf{x}_T\\right) \\prod_{t=1}^T p_\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "with $p(\\mathbf{x}_T)$ a Gaussian prior, $p(\\mathbf{x}_T) \\sim \\mathcal{N}(0,I)$ . We would use $p(\\mathbf{x}_T)$ to sample new data points for generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Variational Lower Bound "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "In the paper, they used the knowledge of the forward pass and design a  Gaussian  reverse kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "$$\n",
    "p_\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t\\right)=\\mathcal{N}\\left(\\mathbf{x}_{t-1} ; \\mu_\\theta\\left(\\mathbf{x}_t, t\\right), \\Sigma_\\theta\\left(\\mathbf{x}_t, t\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "with $\\mu_{\\theta}$ and $\\Sigma_{\\theta}$  parametrized by a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We can write the previous forward kernel\n",
    "$$\n",
    "\\begin{aligned}\n",
    "q\\left(\\mathbf{x}_t \\mid \\mathbf{x}_0\\right) & =\\mathcal{N}\\left(\\mathbf{x}_t ; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0,\\left(1-\\bar{\\alpha}_t\\right) \\mathbf{I}\\right) \\\\\n",
    "& =\\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0+\\epsilon \\sqrt{1-\\bar{\\alpha}_t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "with $ \\epsilon \\sim \\mathcal{N}(0, \\mathbf{I})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "The natural loss would be to optimize under the variational lower bound $L_t$ such that : \n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_{\\mathrm{vlb}} & :=L_0+L_1+\\ldots+L_{T-1}+L_T \\\\\n",
    "L_0 & :=-\\log p_\\theta\\left(x_0 \\mid x_1\\right) \\\\\n",
    "L_{t-1} & :=D_{K L}\\left(q\\left(x_{t-1} \\mid x_t, x_0\\right) \\| p_\\theta\\left(x_{t-1} \\mid x_t\\right)\\right) \\\\\n",
    "L_T & :=D_{K L}\\left(q\\left(x_T \\mid x_0\\right) \\| p\\left(x_T\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "One can show that an alternative loss can be used that only take one parametrized estimator $\\epsilon_{\\theta}$. \\\n",
    "Hint: KL divergences between Gaussian distributions can be computed analytically\n",
    "$$\n",
    "L_{\\text {simple }}(\\theta):=\\mathbb{E}_{t, \\mathbf{x}_0, \\boldsymbol{\\epsilon}}\\left[\\left\\|\\boldsymbol{\\epsilon}-\\boldsymbol{\\epsilon}_\\theta\\left(\\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0+\\sqrt{1-\\bar{\\alpha}_t} \\boldsymbol{\\epsilon}, t\\right)\\right\\|^2\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Let's start implementing the network that predicts $\\widehat \\epsilon(x_t, t; \\theta)$. Note that, as stated by its definition, $\\epsilon$ is the cumulated noise from $t=0$ and not just the noise added at the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResidualMLP(nn.Module):\n",
    "    \"\"\"MLP with residual connections.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_blocks: int,\n",
    "        n_hidden: int,\n",
    "        n_out: int,\n",
    "        activation: str,\n",
    "        name: str = None\n",
    "    ):\n",
    "        super(ResidualMLP, self).__init__()\n",
    "        self._n_blocks = n_blocks\n",
    "        self._n_hidden = n_hidden\n",
    "        self._n_out = n_out\n",
    "        self._activation = getattr(nn.functional, activation)\n",
    "\n",
    "        self.linear_input = nn.Linear(n_out, n_hidden)\n",
    "        self.linear_time = nn.ModuleList([nn.Linear(n_hidden, n_hidden) for _ in range(self._n_blocks)])\n",
    "        self.linear_hidden = nn.Sequential(\n",
    "    nn.ModuleList([nn.Linear(n_hidden, n_hidden) for _ in range(self._n_blocks)]),\n",
    "    nn.ModuleList([nn.Linear(n_hidden, n_hidden) for _ in range(self._n_blocks)])\n",
    "        )\n",
    "        self.linear_output = nn.Linear(n_hidden, n_out)\n",
    "\n",
    "    def forward(self, xt: torch.Tensor, time: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear_input(xt)\n",
    "\n",
    "        for _ in range(self._n_blocks):\n",
    "            h=self._activation(x)\n",
    "            h=self.linear_hidden[_][0](h)\n",
    "            h=h+self.linear_time[_](time)\n",
    "            h=self._activation(h)\n",
    "            h=self.linear_hidden[_][1](h)\n",
    "            x=x+h\n",
    "\n",
    "        outputs = self.linear_output(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Time embeddings\n",
    "\n",
    "As we can see above, the denoiser network needs to get timestep $t$ as an input.\n",
    "\n",
    "However, feeding integers $t=1, 2, ... T$ into the network will not work.\n",
    "\n",
    "[Transformers](https://arxiv.org/abs/1706.03762), when faced with the same problem, proposed to embed timesteps into $d$-dimensional vectors of sinusoids:\n",
    "\n",
    "$$e = [\\; \\sin(w_1 t) \\; \\; \\cos(w_1 t) \\; ... \\; \\sin(w_{d/2} t) \\; \\; \\cos(w_{d/2} t) \\;]$$\n",
    "\n",
    "with $w_i = 1/ 10000^{\\frac{2i}{d}}$.\n",
    "\n",
    "Here is nice blogpost with more intuition: https://kazemnejad.com/blog/transformer_architecture_positional_encoding/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"Time (positional) embedding as in Transformers.\"\"\"\n",
    "\n",
    "    def __init__(self, num_features: int, name: str = None):\n",
    "        super(SinusoidalTimeEmbedding, self).__init__()\n",
    "        self._num_features = num_features\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        assert len(inputs.shape) == 1\n",
    "        half_dim = self._num_features // 2\n",
    "        e = torch.log(torch.tensor(10000.0)) / (half_dim - 1)\n",
    "        embedding = torch.exp(-e * torch.arange(half_dim).float()).to(device)\n",
    "        embedding = inputs.view(-1, 1) * embedding\n",
    "        embedding = torch.cat([torch.cos(embedding), torch.sin(embedding)], dim=-1)\n",
    "        if self._num_features % 2 == 1:\n",
    "            embedding = nn.functional.pad(embedding, (0, 1))\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Now we need to put the two modules together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class NetConfig:\n",
    "    resnet_n_blocks: int = 2\n",
    "    resnet_n_hidden: int = 256\n",
    "    resnet_n_out: int = 2\n",
    "    activation: str = 'elu'\n",
    "    time_embedding_dim: int = 256\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Combines MLP and time embeddings.\"\"\"\n",
    "    def __init__(self, net_config: NetConfig, name: str = None):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self._time_encoder = SinusoidalTimeEmbedding(net_config.time_embedding_dim)\n",
    "        self._predictor = ResidualMLP(\n",
    "            n_blocks=net_config.resnet_n_blocks,\n",
    "            n_hidden=net_config.resnet_n_hidden,\n",
    "            n_out=net_config.resnet_n_out,\n",
    "            activation=net_config.activation\n",
    "        )\n",
    "\n",
    "    def forward(self, noisy_data: torch.Tensor, time: torch.Tensor) -> torch.Tensor:\n",
    "        time_embedding = self._time_encoder(time)\n",
    "        outputs = self._predictor(noisy_data, time_embedding)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Time sampler\n",
    "\n",
    "To compute our loss function, for each example, we need to sample a random timestep. In this trivial case of uniform sampling between step 1 and T, it might be an overkill to implement it as a separate class. It would be more helpful if you're going to explore more exotic diffusion models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "class UniformDiscreteTimeSampler:\n",
    "\n",
    "    def __init__(self, tmin: int, tmax: int):\n",
    "        self._tmin = tmin\n",
    "        self._tmax = tmax\n",
    "\n",
    "    def sample(self, shape: Sequence[int]) -> torch.Tensor:\n",
    "        return torch.randint(low=self._tmin, high=self._tmax, size=shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Full DDPM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q.23 Implement the Simplified loss given a model $\\epsilon_{\\theta}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    \"\"\"Diffusion model.\"\"\"\n",
    "\n",
    "    def __init__(self, diffusion_process, time_sampler, net_config, data_shape):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "\n",
    "        self._process = diffusion_process\n",
    "        self._time_sampler = time_sampler\n",
    "        self._net_config = net_config\n",
    "        self._data_shape = data_shape\n",
    "        self.net_fwd = Net(net_config)\n",
    "\n",
    "    def loss(self, x0: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Computes MSE between the true noise and predicted noise,\n",
    "        i.e. the goal of the network is to correctly predict eps from a noisy observation\n",
    "        xt = alpha(t) * x0 + sigma(t)**2 * eps\"\"\"\n",
    "\n",
    "        ###############\n",
    "        # TO COMPLETE #\n",
    "        ###############\n",
    "\n",
    "        t = ?  # sample time\n",
    "\n",
    "        eps = ?  # sample noise\n",
    "\n",
    "        xt = ?  # corrupt the data\n",
    "\n",
    "        net_outputs = ?  # get net outputs\n",
    "\n",
    "        loss = ?  # compute MSE loss between predicted and true noise\n",
    "\n",
    "        return loss\n",
    "\n",
    "    #Used for sampling \n",
    "    def _reverse_process_step(\n",
    "        self,\n",
    "        xt: torch.Tensor,\n",
    "        t: int,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Computes parameters of a Gaussian p_{\\theta}(x_{t-1}| x_t).\"\"\"\n",
    "\n",
    "        t = t * torch.ones((xt.shape[0],), dtype=torch.int32, device=xt.device)\n",
    "\n",
    "        ###############\n",
    "        # TO COMPLETE #\n",
    "        ###############\n",
    "\n",
    "        eps_pred = ?  # predict epsilon from x_t\n",
    "\n",
    "        sqrt_alpha_t = ? # use self._sqrt_alpha_bar\n",
    "        inv_sqrt_alpha_t = bcast_right(1.0 / sqrt_alpha_t, xt.ndim)\n",
    "\n",
    "        beta_t = ?\n",
    "        beta_t = bcast_right(beta_t, xt.ndim)\n",
    "\n",
    "        inv_sigma_t = ?\n",
    "        inv_sigma_t = bcast_right(inv_sigma_t, xt.ndim)\n",
    "\n",
    "        mean = ?\n",
    "\n",
    "        # DDPM instructs to use either the variance of the forward process\n",
    "        # or the variance of q(x_{t-1}|x_t, x_0). Former is easier.\n",
    "        std = ?\n",
    "\n",
    "        eps = ?\n",
    "\n",
    "        return ?\n",
    "\n",
    "\n",
    "    def sample(self, x0, sample_size):\n",
    "    \"\"\"To generate samples from DDPM, we follow the reverse process.\n",
    "    At each step of the chain, we sample x_{t-1} from p(x_{t-1}| x_t, x0_pred) until we get to x_0.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((sample_size,) + self._data_shape, device=x0.device) #sample pure noise\n",
    "\n",
    "            \n",
    "            ###############\n",
    "            # TO COMPLETE #\n",
    "            ###############\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "Given the noise obtained by the model $\\boldsymbol{\\epsilon}_\\theta\\left(\\mathbf{x}_t, t\\right)$, you can sample $\\mu_{\\theta}(\\mathbf{x}_t,t)$ in order to get a denoised sample point.\n",
    "$$\n",
    "\\mu_{\\theta}(\\mathbf{x}_t,t) = \\frac{1}{\\sqrt{\\alpha_t}}\\left(\\mathbf{x}_t-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta\\left(\\mathbf{x}_t, t\\right)\\right)\n",
    "$$ \n",
    "\n",
    "\n",
    "The _reverse_process_step function sample $x_{t-1} \\sim p_\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t\\right)$ where\n",
    "$$\n",
    "p_\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t\\right)=\\mathcal{N}\\left(\\mathbf{x}_{t-1} ; \\mu_\\theta\\left(\\mathbf{x}_t, t\\right), \\Sigma_\\theta\\left(\\mathbf{x}_t, t\\right)\\right)\n",
    "$$\n",
    "and we set $$\\Sigma_\\theta\\left(\\mathbf{x}_t, t\\right) = \\beta_{t}\\boldsymbol{I}$$\n",
    "\n",
    "Thus $$x_{t-1} = \\mu_{\\theta}(\\mathbf{x}_t,t) + \\sqrt{\\beta_t}\\epsilon$$ where $$\\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$$\n",
    "\n",
    "**Q.24 Build the sampling function that allows you from inputs $\\mathbf{x}_t$ and $t$ to obtain $\\mu_{\\theta}(\\mathbf{x}_t,t)$ and $x_{t-1}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# create the model\n",
    "diffusion_process = DiscreteDDPMProcess(num_diffusion_timesteps=1000)\n",
    "time_sampler = UniformDiscreteTimeSampler(diffusion_process.tmin, diffusion_process.tmax)\n",
    "model = DiffusionModel(diffusion_process, time_sampler, net_config=NetConfig(), data_shape=(2,)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "We will use a learning rate scheduler with a warmup. \\\n",
    "You will have to install the library pytorch_warmup with \"pip install -U pytorch_warmup\": https://github.com/Tony-Y/pytorch_warmup \\\n",
    "Our learning rate schedule will have the following shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "![Denoisingdiagram](./lr_with_warmup.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "import pytorch_warmup as warmup\n",
    "\n",
    "training_steps = 50000\n",
    "\n",
    "warmup_period=1000 #this is the increasing part of the learning rate schedule\n",
    "num_steps = training_steps\n",
    "t0 = num_steps // 1\n",
    "lr_min = 3e-12\n",
    "max_step = t0 * 1 + warmup_period #you can also create cycle but we won't touch it here\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=t0, T_mult=1, eta_min=lr_min)\n",
    "\n",
    "warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "##### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q.25 Train $\\epsilon_{\\theta}(\\mathbf{x},t)$ that take as entry a transformed vector $\\mathbf{x}$ and  $t$ a number of time $\\mathbf{x}$ passed through the forward process  and return  a direct estimate of  the noise $\\epsilon$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=1024\n",
    "\n",
    "for step in range(training_steps):\n",
    "    #generate batch on the fly\n",
    "\n",
    "    ###############\n",
    "    # TO COMPLETE #\n",
    "    ###############\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f'Step: {step}, Loss: {loss:.5f}')\n",
    "\n",
    "    if step % 10000 == 0:\n",
    "        with torch.no_grad():\n",
    "            samples = ? # create new samples\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.scatter(samples[:, 0], samples[:, 1], s=1, alpha=0.5)\n",
    "        plt.show()\n",
    "\n",
    "    with warmup_scheduler.dampening():\n",
    "        if warmup_scheduler.last_step + 1 >= warmup_period:\n",
    "            lr_scheduler.step()\n",
    "        if warmup_scheduler.last_step + 1 >= max_step:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Ablation study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q.26 Perform ablations experiments on hyperparameters, such as: learning rate (try constant learning rate with different values), batch size, the number of timesteps, the positional embedding for timestep (remove it), the hidden size, number of epochs, skip connections**\n",
    "\n",
    "For a given ablation experiment (they ought to be done separately!), you should plot generated samples at few given timesteps (if compute resources is limited, do it for one timestep).\n",
    "\n",
    "Note: you don't have to do all of these experiments, but the bigger is your group, the more you should do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "#### Generation/Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q.27  Generate samples and plot them at different timestep of the chain. Check how real & synthetic distribution overlap, compare the densities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "---\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "**Q.28: As a conclusion, how would you compare the advantages and shortcomings of GANs, VAEs, Flow Matching and Denoising Models ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_ktag": "WmgGMz8cvAsg"
   },
   "source": [
    "> (Write your answer here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kfiletag": "WmgGMz8cvAsg",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
